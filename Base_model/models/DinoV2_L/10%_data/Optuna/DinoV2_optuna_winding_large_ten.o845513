### Starting TaskPrologue of job 845513 on tg092 at Fri 21 Jun 2024 06:28:11 PM CEST
Running on cores 96-127 with governor ondemand
Fri Jun 21 18:28:11 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:C1:00.0 Off |                    0 |
| N/A   32C    P0             52W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

[I 2024-06-21 18:29:13,154] Using an existing study with name 'DinoV2_optuna_winding_large_ten' instead of creating a new one.
Best trial's number:  50
Best score: 0.8903234501678569
Best hyperparameters:
image_size: 224
batch_size: 8
learning_rate: 7.5e-07
fc_units: 2048
fc_units_2: 2048
Number of trials completed: 22
Number of pruned trials: 63
Total number of trails completed: 85
Number of trials to run: 15
==================== Training of trial number:86 ====================
Image size: 224
Batch size: 4
Learning rate: 0.0000050000
Fully connected units 1: 128
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
/home/hpc/iwfa/iwfa054h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/hpc/iwfa/iwfa054h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/hpc/iwfa/iwfa054h/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
[I 2024-06-21 18:32:45,222] Trial 86 pruned. 
Epoch 1/100, Training Loss: 0.1716, Training F1-score: 0.9601, Validation Loss: 0.2922, Validation F1-score: 0.8459
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:87 ====================
Image size: 224
Batch size: 8
Learning rate: 0.0005000000
Fully connected units 1: 1024
Fully connected units 2: 256
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 18:35:49,667] Trial 87 pruned. 
Epoch 1/100, Training Loss: 0.6808, Training F1-score: 0.3377, Validation Loss: 0.6498, Validation F1-score: 0.2304
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:88 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0002500000
Fully connected units 1: 256
Fully connected units 2: 512
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 18:38:38,749] Trial 88 pruned. 
Epoch 1/100, Training Loss: 0.6754, Training F1-score: 0.3561, Validation Loss: 0.6529, Validation F1-score: 0.2304
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:89 ====================
Image size: 224
Batch size: 4
Learning rate: 0.0000007500
Fully connected units 1: 2048
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 18:42:01,495] Trial 89 pruned. 
Epoch 1/100, Training Loss: 0.1540, Training F1-score: 0.9506, Validation Loss: 0.2375, Validation F1-score: 0.7516
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:90 ====================
Image size: 224
Batch size: 8
Learning rate: 0.0000005000
Fully connected units 1: 2048
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 18:45:05,994] Trial 90 pruned. 
Epoch 1/100, Training Loss: 0.2455, Training F1-score: 0.9128, Validation Loss: 0.2702, Validation F1-score: 0.7247
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:91 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
Epoch 1/100, Training Loss: 0.1626, Training F1-score: 0.9594, Validation Loss: 0.2870, Validation F1-score: 0.8658
Best F1-score till now on the current trail on Validation data: 0.8657788055223866
Epoch 2/100, Training Loss: 0.0692, Training F1-score: 0.9817, Validation Loss: 0.3494, Validation F1-score: 0.8417
Epoch 3/100, Training Loss: 0.0473, Training F1-score: 0.9850, Validation Loss: 0.3150, Validation F1-score: 0.7823
Epoch 4/100, Training Loss: 0.0462, Training F1-score: 0.9828, Validation Loss: 0.2392, Validation F1-score: 0.8796
Best F1-score till now on the current trail on Validation data: 0.8796280300684413
Epoch 5/100, Training Loss: 0.0392, Training F1-score: 0.9871, Validation Loss: 0.3055, Validation F1-score: 0.8471
Epoch 6/100, Training Loss: 0.0290, Training F1-score: 0.9893, Validation Loss: 0.3736, Validation F1-score: 0.7566
Epoch 7/100, Training Loss: 0.0300, Training F1-score: 0.9881, Validation Loss: 0.3539, Validation F1-score: 0.8399
Epoch 8/100, Training Loss: 0.0259, Training F1-score: 0.9896, Validation Loss: 0.3295, Validation F1-score: 0.8708
Epoch 9/100, Training Loss: 0.0224, Training F1-score: 0.9912, Validation Loss: 0.3960, Validation F1-score: 0.8558
Epoch 10/100, Training Loss: 0.0216, Training F1-score: 0.9910, Validation Loss: 0.3628, Validation F1-score: 0.8678
Epoch 11/100, Training Loss: 0.0212, Training F1-score: 0.9919, Validation Loss: 0.3639, Validation F1-score: 0.8469
Epoch 12/100, Training Loss: 0.0193, Training F1-score: 0.9915, Validation Loss: 0.4713, Validation F1-score: 0.8503
Epoch 13/100, Training Loss: 0.0177, Training F1-score: 0.9926, Validation Loss: 0.4075, Validation F1-score: 0.8603
[I 2024-06-21 19:23:45,373] Trial 91 finished with value: 0.8903234501678569 and parameters: {'image_size': 224, 'batch_size': 16, 'learning_rate': 7.5e-06, 'fc_units': 256, 'fc_units_2': 2048}. Best is trial 50 with value: 0.8903234501678569.
Epoch 14/100, Training Loss: 0.0265, Training F1-score: 0.9879, Validation Loss: 0.4998, Validation F1-score: 0.8276
Early stopping triggered after 14 epochs.
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:92 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 19:26:34,444] Trial 92 pruned. 
Epoch 1/100, Training Loss: 0.1713, Training F1-score: 0.9498, Validation Loss: 0.2709, Validation F1-score: 0.8602
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:93 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0050000000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 19:29:23,793] Trial 93 pruned. 
Epoch 1/100, Training Loss: 0.7323, Training F1-score: 0.3772, Validation Loss: 0.6707, Validation F1-score: 0.4063
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:94 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
Epoch 1/100, Training Loss: 0.1703, Training F1-score: 0.9535, Validation Loss: 0.2572, Validation F1-score: 0.8607
Best F1-score till now on the current trail on Validation data: 0.8607351290162241
Epoch 2/100, Training Loss: 0.0792, Training F1-score: 0.9790, Validation Loss: 0.3483, Validation F1-score: 0.6451
Epoch 3/100, Training Loss: 0.0513, Training F1-score: 0.9839, Validation Loss: 0.2347, Validation F1-score: 0.8681
Best F1-score till now on the current trail on Validation data: 0.8680697286953523
Epoch 4/100, Training Loss: 0.0409, Training F1-score: 0.9858, Validation Loss: 0.2490, Validation F1-score: 0.8397
Epoch 5/100, Training Loss: 0.0382, Training F1-score: 0.9861, Validation Loss: 0.4192, Validation F1-score: 0.6722
Epoch 6/100, Training Loss: 0.0320, Training F1-score: 0.9881, Validation Loss: 0.3676, Validation F1-score: 0.8585
Epoch 7/100, Training Loss: 0.0262, Training F1-score: 0.9891, Validation Loss: 0.2194, Validation F1-score: 0.8853
Best F1-score till now on the current trail on Validation data: 0.8852958494270983
Epoch 8/100, Training Loss: 0.0258, Training F1-score: 0.9897, Validation Loss: 0.3809, Validation F1-score: 0.8520
Epoch 9/100, Training Loss: 0.0272, Training F1-score: 0.9880, Validation Loss: 0.3074, Validation F1-score: 0.8660
Epoch 10/100, Training Loss: 0.0230, Training F1-score: 0.9900, Validation Loss: 0.3343, Validation F1-score: 0.8714
Epoch 11/100, Training Loss: 0.0179, Training F1-score: 0.9937, Validation Loss: 0.4029, Validation F1-score: 0.8336
Epoch 12/100, Training Loss: 0.0175, Training F1-score: 0.9929, Validation Loss: 0.3505, Validation F1-score: 0.8756
Epoch 13/100, Training Loss: 0.0162, Training F1-score: 0.9927, Validation Loss: 0.3903, Validation F1-score: 0.8693
Epoch 14/100, Training Loss: 0.0152, Training F1-score: 0.9935, Validation Loss: 0.3753, Validation F1-score: 0.8714
Epoch 15/100, Training Loss: 0.0331, Training F1-score: 0.9885, Validation Loss: 0.3645, Validation F1-score: 0.8624
Epoch 16/100, Training Loss: 0.0226, Training F1-score: 0.9905, Validation Loss: 0.4922, Validation F1-score: 0.8435
[I 2024-06-21 20:16:13,560] Trial 94 finished with value: 0.8903234501678569 and parameters: {'image_size': 224, 'batch_size': 16, 'learning_rate': 7.5e-06, 'fc_units': 256, 'fc_units_2': 2048}. Best is trial 50 with value: 0.8903234501678569.
Epoch 17/100, Training Loss: 0.0159, Training F1-score: 0.9926, Validation Loss: 0.4760, Validation F1-score: 0.8465
Early stopping triggered after 17 epochs.
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:95 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 20:19:02,589] Trial 95 pruned. 
Epoch 1/100, Training Loss: 0.1649, Training F1-score: 0.9546, Validation Loss: 0.3113, Validation F1-score: 0.8297
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:96 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 20:21:51,680] Trial 96 pruned. 
Epoch 1/100, Training Loss: 0.1526, Training F1-score: 0.9585, Validation Loss: 0.3241, Validation F1-score: 0.8182
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:97 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
Epoch 1/100, Training Loss: 0.1672, Training F1-score: 0.9544, Validation Loss: 0.2349, Validation F1-score: 0.8824
Best F1-score till now on the current trail on Validation data: 0.8824003891935144
Epoch 2/100, Training Loss: 0.0694, Training F1-score: 0.9833, Validation Loss: 0.2820, Validation F1-score: 0.7594
Epoch 3/100, Training Loss: 0.0513, Training F1-score: 0.9842, Validation Loss: 0.3080, Validation F1-score: 0.8434
Epoch 4/100, Training Loss: 0.0457, Training F1-score: 0.9838, Validation Loss: 0.3113, Validation F1-score: 0.8181
Epoch 5/100, Training Loss: 0.0396, Training F1-score: 0.9859, Validation Loss: 0.3547, Validation F1-score: 0.8140
Epoch 6/100, Training Loss: 0.0339, Training F1-score: 0.9876, Validation Loss: 0.3107, Validation F1-score: 0.8580
Epoch 7/100, Training Loss: 0.0278, Training F1-score: 0.9888, Validation Loss: 0.3136, Validation F1-score: 0.8333
Epoch 8/100, Training Loss: 0.0223, Training F1-score: 0.9899, Validation Loss: 0.3633, Validation F1-score: 0.8072
Epoch 9/100, Training Loss: 0.0211, Training F1-score: 0.9905, Validation Loss: 0.3259, Validation F1-score: 0.7909
Epoch 10/100, Training Loss: 0.0216, Training F1-score: 0.9900, Validation Loss: 0.3504, Validation F1-score: 0.8543
[I 2024-06-21 20:52:24,790] Trial 97 finished with value: 0.8903234501678569 and parameters: {'image_size': 224, 'batch_size': 16, 'learning_rate': 7.5e-06, 'fc_units': 256, 'fc_units_2': 2048}. Best is trial 50 with value: 0.8903234501678569.
Epoch 11/100, Training Loss: 0.0182, Training F1-score: 0.9918, Validation Loss: 0.3390, Validation F1-score: 0.8526
Early stopping triggered after 11 epochs.
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:98 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
Epoch 1/100, Training Loss: 0.1602, Training F1-score: 0.9567, Validation Loss: 0.2531, Validation F1-score: 0.8679
Best F1-score till now on the current trail on Validation data: 0.8678691072999065
Epoch 2/100, Training Loss: 0.0621, Training F1-score: 0.9856, Validation Loss: 0.3429, Validation F1-score: 0.8442
Epoch 3/100, Training Loss: 0.0528, Training F1-score: 0.9842, Validation Loss: 0.3387, Validation F1-score: 0.8533
Epoch 4/100, Training Loss: 0.0396, Training F1-score: 0.9863, Validation Loss: 0.3060, Validation F1-score: 0.8728
Best F1-score till now on the current trail on Validation data: 0.8727722086720853
Epoch 5/100, Training Loss: 0.0335, Training F1-score: 0.9879, Validation Loss: 0.3627, Validation F1-score: 0.8470
Epoch 6/100, Training Loss: 0.0539, Training F1-score: 0.9796, Validation Loss: 0.3111, Validation F1-score: 0.8648
Epoch 7/100, Training Loss: 0.0305, Training F1-score: 0.9877, Validation Loss: 0.3414, Validation F1-score: 0.8513
Epoch 8/100, Training Loss: 0.0249, Training F1-score: 0.9900, Validation Loss: 0.3737, Validation F1-score: 0.8527
Epoch 9/100, Training Loss: 0.0225, Training F1-score: 0.9912, Validation Loss: 0.4154, Validation F1-score: 0.8051
Epoch 10/100, Training Loss: 0.0250, Training F1-score: 0.9902, Validation Loss: 0.4547, Validation F1-score: 0.8414
Epoch 11/100, Training Loss: 0.0212, Training F1-score: 0.9903, Validation Loss: 0.4031, Validation F1-score: 0.8420
Epoch 12/100, Training Loss: 0.0203, Training F1-score: 0.9920, Validation Loss: 0.4490, Validation F1-score: 0.8396
Epoch 13/100, Training Loss: 0.0205, Training F1-score: 0.9907, Validation Loss: 0.4206, Validation F1-score: 0.8092
[I 2024-06-21 21:31:00,270] Trial 98 finished with value: 0.8903234501678569 and parameters: {'image_size': 224, 'batch_size': 16, 'learning_rate': 7.5e-06, 'fc_units': 256, 'fc_units_2': 2048}. Best is trial 50 with value: 0.8903234501678569.
Epoch 14/100, Training Loss: 0.0205, Training F1-score: 0.9909, Validation Loss: 0.5414, Validation F1-score: 0.8279
Early stopping triggered after 14 epochs.
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:99 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
Epoch 1/100, Training Loss: 0.1562, Training F1-score: 0.9591, Validation Loss: 0.2392, Validation F1-score: 0.8809
Best F1-score till now on the current trail on Validation data: 0.8808508599233073
Epoch 2/100, Training Loss: 0.0696, Training F1-score: 0.9802, Validation Loss: 0.3562, Validation F1-score: 0.8456
Epoch 3/100, Training Loss: 0.0504, Training F1-score: 0.9848, Validation Loss: 0.3151, Validation F1-score: 0.8333
Epoch 4/100, Training Loss: 0.0431, Training F1-score: 0.9854, Validation Loss: 0.2711, Validation F1-score: 0.8110
Epoch 5/100, Training Loss: 0.0331, Training F1-score: 0.9884, Validation Loss: 0.3079, Validation F1-score: 0.8591
Epoch 6/100, Training Loss: 0.0287, Training F1-score: 0.9881, Validation Loss: 0.3369, Validation F1-score: 0.8448
Epoch 7/100, Training Loss: 0.0293, Training F1-score: 0.9870, Validation Loss: 0.3240, Validation F1-score: 0.8548
Epoch 8/100, Training Loss: 0.0256, Training F1-score: 0.9901, Validation Loss: 0.3996, Validation F1-score: 0.8449
Epoch 9/100, Training Loss: 0.0200, Training F1-score: 0.9923, Validation Loss: 0.3629, Validation F1-score: 0.7557
Epoch 10/100, Training Loss: 0.0199, Training F1-score: 0.9915, Validation Loss: 0.4083, Validation F1-score: 0.8486
[I 2024-06-21 22:01:20,103] Trial 99 finished with value: 0.8903234501678569 and parameters: {'image_size': 224, 'batch_size': 16, 'learning_rate': 7.5e-06, 'fc_units': 256, 'fc_units_2': 2048}. Best is trial 50 with value: 0.8903234501678569.
Epoch 11/100, Training Loss: 0.0167, Training F1-score: 0.9934, Validation Loss: 0.4650, Validation F1-score: 0.8454
Early stopping triggered after 11 epochs.
Best F1-score till now on Validation data: 0.8903234501678569
==================== Training of trial number:100 ====================
Image size: 224
Batch size: 16
Learning rate: 0.0000075000
Fully connected units 1: 256
Fully connected units 2: 2048
Best F1-score on Validation data until now: 0.8903234501678569
[I 2024-06-21 22:04:09,267] Trial 100 pruned. 
Epoch 1/100, Training Loss: 0.1613, Training F1-score: 0.9606, Validation Loss: 0.2442, Validation F1-score: 0.8523
Best F1-score till now on Validation data: 0.8903234501678569
Best trial's number:  50
Best score: 0.8903234501678569
Best hyperparameters:
image_size: 224
batch_size: 8
learning_rate: 7.5e-07
fc_units: 2048
fc_units_2: 2048
=== JOB_STATISTICS ===
=== current date     : Fri 21 Jun 2024 10:04:13 PM CEST
= Job-ID             : 845513 on tinygpu
= Job-Name           : DinoV2_optuna_winding_large_ten
= Job-Command        : /home/woody/iwfa/iwfa054h/batch.sh
= Initial workdir    : /home/woody/iwfa/iwfa054h
= Queue/Partition    : a100
= Slurm account      : iwfa with QOS=normal
= Requested resources:  for 23:59:00
= Elapsed runtime    : 03:36:14
= Total RAM usage    : 2.3 GiB of requested  GiB (%)   
= Node list          : tg092
= Subm/Elig/Start/End: 2024-06-21T18:27:58 / 2024-06-21T18:27:58 / 2024-06-21T18:27:59 / 2024-06-21T22:04:13
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           69.0G   104.9G   209.7G        N/A     167K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:C1:00.0, 3053175, 97 %, 19 %, 14760 MiB, 12899549 ms
